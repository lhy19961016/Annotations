{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import albumentations as A\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms as transforms\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\n\n# https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/\n#https://discuss.pytorch.org/t/how-to-plot-train-and-validation-accuracy-graph/105524\nimport matplotlib\nmatplotlib.use('agg')\nimport matplotlib.pyplot as plt\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:30:43.638368Z","iopub.execute_input":"2021-12-19T17:30:43.638677Z","iopub.status.idle":"2021-12-19T17:30:43.646680Z","shell.execute_reply.started":"2021-12-19T17:30:43.638645Z","shell.execute_reply":"2021-12-19T17:30:43.645336Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"config = {\n    'batch_size': 64,\n    'num_workers': 2,\n    'lr': 0.001,\n    'epochs': 10,\n    'device': 'cuda',\n    'image_size': 224\n}\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:30:45.750848Z","iopub.execute_input":"2021-12-19T17:30:45.751491Z","iopub.status.idle":"2021-12-19T17:30:45.809778Z","shell.execute_reply.started":"2021-12-19T17:30:45.751454Z","shell.execute_reply":"2021-12-19T17:30:45.808634Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# transforms = A.Compose(\n#     [A.Resize(height=config[\"image_size\"], width=config[\"image_size\"], p=1)],\n#     torchvision.transforms.RandomHorizontalFlip(p=0.5)\n#     p=1,\n# )\n#------------------------------------(Предпроцесс)-------------------------------------\n#https://pytorch.org/vision/main/generated/torchvision.transforms.Compose.html\n#https://pytorch.org/vision/main/transforms.html\ntransform_train = transforms.Compose([transforms.Resize(config['image_size']),\n                                transforms.RandomHorizontalFlip(0.5),\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\ntransform_test = transforms.Compose([transforms.Resize(config['image_size']),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:30:48.388394Z","iopub.execute_input":"2021-12-19T17:30:48.388706Z","iopub.status.idle":"2021-12-19T17:30:48.398650Z","shell.execute_reply.started":"2021-12-19T17:30:48.388675Z","shell.execute_reply":"2021-12-19T17:30:48.397626Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#------------------------------------Datasets process--------------------------------------\n#https://pillow.readthedocs.io/en/stable/handbook/tutorial.html\n#https://www.geeksforgeeks.org/python-pil-image-open-method/\nfrom PIL import Image\nclass RealFakeDataset(Dataset):\n    def __init__(self, data_path, target=None, is_test=False, augmentation=None):\n        super().__init__()\n        self.data_path = data_path\n        self.target = target\n        self.is_test = is_test\n        self.augmentation = augmentation\n\n    def __len__(self):\n        return len(self.data_path)\n\n    def __getitem__(self, item):\n#         image = cv2.imread(self.data_path[item])\n        image = Image.open(self.data_path[item]).convert('RGB') # switch to 3 channels\n        if self.augmentation:\n            image = self.augmentation(image)\n#             sample = self.augmentation(image=image)\n#             image = sample[\"image\"]\n        \n        if self.is_test:\n            return torch.tensor(np.moveaxis(image, -1, 0), dtype=torch.float)\n#         return torch.tensor(np.moveaxis(image, -1, 0), dtype=torch.float), torch.tensor(\n#             self.target[item], dtype=torch.float\n        return image, torch.tensor(self.target[item], dtype=torch.float)\n# image = Image.open(r\"../input/cmc-robust-real-vs-fake/test/100.jpg\").convert('RGB')\n# image.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:37:10.078839Z","iopub.execute_input":"2021-12-19T17:37:10.079761Z","iopub.status.idle":"2021-12-19T17:37:10.090649Z","shell.execute_reply.started":"2021-12-19T17:37:10.079721Z","shell.execute_reply":"2021-12-19T17:37:10.089640Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#-----------------------------------File Read---------------------------------------------\ndf = pd.read_csv(\"../input/cmc-robust-real-vs-fake/train.csv\")\ndf.label","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:30:52.947347Z","iopub.execute_input":"2021-12-19T17:30:52.948240Z","iopub.status.idle":"2021-12-19T17:30:53.017017Z","shell.execute_reply.started":"2021-12-19T17:30:52.948190Z","shell.execute_reply":"2021-12-19T17:30:53.016006Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#-----------------------------------Случайно разделить обучающее и тестовое множества-------------------------------\ntrain, val = train_test_split(df)\nprint(train[0:3], val[0:3])","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:30:55.640490Z","iopub.execute_input":"2021-12-19T17:30:55.641084Z","iopub.status.idle":"2021-12-19T17:30:55.665882Z","shell.execute_reply.started":"2021-12-19T17:30:55.641043Z","shell.execute_reply":"2021-12-19T17:30:55.664841Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_paths = [f\"../input/cmc-robust-real-vs-fake/train/{i}.jpg\" for i in train[\"id\"].values]\ntrain_target = train[\"label\"].values\ntrain_target[0:3]","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:30:57.974356Z","iopub.execute_input":"2021-12-19T17:30:57.975164Z","iopub.status.idle":"2021-12-19T17:30:58.051223Z","shell.execute_reply.started":"2021-12-19T17:30:57.975128Z","shell.execute_reply":"2021-12-19T17:30:58.050289Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"valid_paths = [f\"../input/cmc-robust-real-vs-fake/train/{i}.jpg\" for i in val[\"id\"].values]\nvalid_target = val[\"label\"].values","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:31:01.443115Z","iopub.execute_input":"2021-12-19T17:31:01.443429Z","iopub.status.idle":"2021-12-19T17:31:01.474033Z","shell.execute_reply.started":"2021-12-19T17:31:01.443397Z","shell.execute_reply":"2021-12-19T17:31:01.473143Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_dataset = RealFakeDataset(\n    train_paths,\n    train_target,\n    is_test=False,\n    augmentation=transform_train,\n)\nvalid_dataset = RealFakeDataset(\n    valid_paths,\n    valid_target,\n    is_test=False,\n    augmentation=transform_test\n)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=config[\"batch_size\"],\n    shuffle=True,\n    num_workers=config[\"num_workers\"],\n    drop_last=True,\n)\nvalid_loader = DataLoader(\n    valid_dataset,\n    batch_size=config[\"batch_size\"],\n    shuffle=False,\n    num_workers=config[\"num_workers\"],\n    drop_last=False,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:32:33.583896Z","iopub.execute_input":"2021-12-19T17:32:33.584635Z","iopub.status.idle":"2021-12-19T17:32:33.594106Z","shell.execute_reply.started":"2021-12-19T17:32:33.584601Z","shell.execute_reply":"2021-12-19T17:32:33.592926Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# materials: 1) https://arxiv.org/abs/1512.03385 2) https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py \n# 3) https://programmerall.com/article/8807556331/ 4) https://blog.csdn.net/weixin_36979214/article/details/108879684\n                \nclass ResNetBasicBlock(nn.Module) :\n    def __init__ (self, in_channels , out_channels, stride) :\n        super(ResNetBasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d (out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n    def forward (self, x):\n        output = self.conv1(x)\n        output = F.relu(self.bn1(output))\n        output = self.conv2(output)\n        output = self.bn2(output)\n        return F.relu(x + output)\n\nclass ResNetDownBlock(nn.Module) :\n    def __init__(self, in_channels, out_channels, stride) :\n        super(ResNetDownBlock, self).__init__()\n        self.conv1 = nn. Conv2d(in_channels, out_channels, kernel_size=3, stride=stride[0], padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn. Conv2d(out_channels, out_channels, kernel_size=3, stride=stride[1], padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.extra = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride[0], padding=0),\n        nn.BatchNorm2d(out_channels))\n    \n    def forward(self, x):\n        extra_x = self.extra(x)\n        output = self.conv1(x)\n        out = F.relu(self.bn1(output))\n    \n        out = self.conv2(out)\n        out = self.bn2(out)\n        return F.relu(extra_x + out)\n\nclass ResNet18_For_FakeAndTrue(nn.Module):\n    def __init__(self):\n        super(ResNet18_For_FakeAndTrue, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2 , padding=1)\n        \n        self.layer1 = nn.Sequential(ResNetBasicBlock(64, 64, 1),\n        ResNetBasicBlock(64, 64, 1))\n        self.layer2 = nn.Sequential(ResNetDownBlock (64, 128, [2, 1]),\n        ResNetBasicBlock(128, 128, 1))\n        self.layer3 = nn.Sequential(ResNetDownBlock(128, 256, [2, 1]),\n        ResNetBasicBlock(256, 256, 1) )\n        self.layer4 = nn.Sequential(ResNetDownBlock (256, 512, [2, 1]),\n        ResNetBasicBlock(512, 512, 1))\n        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n        self.fc = nn.Linear(512, 1) # число класса == 1\n        \n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.avgpool(out)\n        out = out.reshape(x.shape [0], -1)\n        out = self.fc(out)\n        return out\n","metadata":{"execution":{"iopub.status.busy":"2021-12-19T15:21:35.63916Z","iopub.execute_input":"2021-12-19T15:21:35.639737Z","iopub.status.idle":"2021-12-19T15:21:35.662314Z","shell.execute_reply.started":"2021-12-19T15:21:35.6397Z","shell.execute_reply":"2021-12-19T15:21:35.661609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#---------------------------------------новая модель----------------------\n# model = ResNet18_For_FakeAndTrue()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T15:21:35.665494Z","iopub.execute_input":"2021-12-19T15:21:35.666011Z","iopub.status.idle":"2021-12-19T15:21:35.671804Z","shell.execute_reply.started":"2021-12-19T15:21:35.665974Z","shell.execute_reply":"2021-12-19T15:21:35.671065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-------------------------------------Снова-------------------------\nmodel = torch.load(\"../input/final-version-competition/my_model.pt\")","metadata":{"execution":{"iopub.status.busy":"2021-12-19T15:21:35.672763Z","iopub.execute_input":"2021-12-19T15:21:35.672934Z","iopub.status.idle":"2021-12-19T15:21:40.233233Z","shell.execute_reply.started":"2021-12-19T15:21:35.672909Z","shell.execute_reply":"2021-12-19T15:21:40.232368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#------------- Не успешно:(--------------\n# Graph_Network = SummaryWriter('./Graph_CNN')\n# image_s,label_s = next(iter(train_loader)) \n# Graph_Network.add_graph(model, image_s)\n# Graph_Network.close()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T15:21:40.236436Z","iopub.execute_input":"2021-12-19T15:21:40.236651Z","iopub.status.idle":"2021-12-19T15:21:40.241889Z","shell.execute_reply.started":"2021-12-19T15:21:40.236626Z","shell.execute_reply":"2021-12-19T15:21:40.241109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(config[\"device\"])","metadata":{"execution":{"iopub.status.busy":"2021-12-19T15:21:40.243546Z","iopub.execute_input":"2021-12-19T15:21:40.244073Z","iopub.status.idle":"2021-12-19T15:21:40.258274Z","shell.execute_reply.started":"2021-12-19T15:21:40.244036Z","shell.execute_reply":"2021-12-19T15:21:40.25749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-----------------------------------Я попробовал другой адаптивный оптимизатор: Adamax----------------------\ncriterion = F.binary_cross_entropy_with_logits\noptimizer = torch.optim.Adamax(model.parameters(), lr=config[\"lr\"])\n#optimizer = torch.optim.SGD(model.parameters(), lr=config[\"lr\"], momentum=0.9, weight_decay=5e-4)\n#optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])","metadata":{"execution":{"iopub.status.busy":"2021-12-19T15:21:40.25979Z","iopub.execute_input":"2021-12-19T15:21:40.260035Z","iopub.status.idle":"2021-12-19T15:21:40.264851Z","shell.execute_reply.started":"2021-12-19T15:21:40.260001Z","shell.execute_reply":"2021-12-19T15:21:40.263918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#----------------------------------------Функция обучения--------------------------------\ndef train_fn(data_loader, model, optimizer, criterion, device):\n    sum_loss = 0\n    model.train()\n\n    for bi, batch in tqdm(enumerate(data_loader), total=len(data_loader)):\n        X, targets = batch\n        X = X.to(device)\n        targets = targets.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(X)\n        outputs = outputs.squeeze(1)\n\n        loss = criterion(outputs, targets)\n        loss.backward()\n        sum_loss += loss.detach().item()\n\n        optimizer.step()\n\n    return sum_loss / len(data_loader)\n\n#--------------------------------------Функция оценивания--------------------------\ndef eval_fn(data_loader, model, criterion, device):\n    model.eval()\n    sum_loss = 0\n    fin_targets = []\n    fin_outputs = []\n    with torch.no_grad():\n        for bi, batch in tqdm(enumerate(data_loader), total=len(data_loader)):\n            X, targets = batch\n            X = X.to(device)\n            targets = targets.to(device)\n\n            outputs = model(X)\n            outputs = outputs.squeeze(1)\n\n            loss = criterion(outputs, targets)\n            sum_loss += loss.detach().item()\n            \n            fin_targets.extend(targets.tolist())\n            fin_outputs.extend(outputs.tolist())\n\n    roc = roc_auc_score(fin_targets, fin_outputs)\n    return sum_loss / len(data_loader), roc\n\ndef predict_fn(data_loader, model, device):\n    model.eval()\n    fin_outputs = []\n    with torch.no_grad():\n        for bi, batch in tqdm(enumerate(data_loader), total=len(data_loader)):\n            X = batch\n            X = X.to(device)\n\n            outputs = model(X)\n            outputs = outputs.squeeze(1)\n\n            fin_outputs.extend(outputs.tolist())\n\n    return fin_outputs","metadata":{"execution":{"iopub.status.busy":"2021-12-19T15:21:40.266272Z","iopub.execute_input":"2021-12-19T15:21:40.266643Z","iopub.status.idle":"2021-12-19T15:21:40.281659Z","shell.execute_reply.started":"2021-12-19T15:21:40.266609Z","shell.execute_reply":"2021-12-19T15:21:40.280684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counter_loss = 0\nbest_loss = 0.0007\nval_loss_set = []\ntrain_loss_set =[]\nfor _ in range(config[\"epochs\"]):\n    train_loss = train_fn(train_loader, model, optimizer, criterion, config[\"device\"])\n    val_loss, metric = eval_fn(valid_loader, model, criterion, config[\"device\"])\n    val_loss_set.append(val_loss)\n    train_loss_set.append(train_loss)\n    \n    print(\n        f\"\"\"\n        Train loss = {train_loss},\n        Validation loss = {val_loss},\n        ROC AUC = {metric}\n        \"\"\"\n    )\n    if val_loss < best_loss:\n        print(\"Model saved!\")\n        best_loss = val_loss\n        torch.save(model,\"./my_model.pt\")\n    else:\n        counter_loss += 1\n        if counter_loss == int(config[\"epochs\"] * 0.4):\n            print(\"The point is lost in the valley\")\n            break\n        else:\n            print(\"The point is trying to find way to bottom of the hill\")\nplt.title(\"Model Loss\")\nplt.plot(train_loss_set,label=\"train_loss\")\nplt.plot(val_loss_set,label=\"val_loss\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"Loss\")\nplt.legend(['train','valid'], loc='upper left')\nplt.show()\nplt.savefig('./loss_graph.png')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T15:21:40.283201Z","iopub.execute_input":"2021-12-19T15:21:40.283489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RealFakeDataset(Dataset):\n    def __init__(self, data_path, target=None, is_test=False, augmentation=None):\n        super().__init__()\n        self.data_path = data_path\n        self.target = target\n        self.is_test = is_test\n        self.augmentation = augmentation\n\n    def __len__(self):\n        return len(self.data_path)\n\n    def __getitem__(self, item):\n#         image = cv2.imread(self.data_path[item])\n        image = Image.open(self.data_path[item]).convert('RGB')\n        if self.augmentation:\n            image = self.augmentation(image)\n#             sample = self.augmentation(image=image)\n#             image = sample[\"image\"]\n        \n        if self.is_test:\n#             return torch.tensor(np.moveaxis(image, -1, 0), dtype=torch.float)\n            return image\n#         return torch.tensor(np.moveaxis(image, -1, 0), dtype=torch.float), torch.tensor(\n#             self.target[item], dtype=torch.float\n        return image, torch.tensor(self.target[item], dtype=torch.float)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel = torch.load(\"./my_model.pt\")\nmodel.to(config[\"device\"])\nmodel.eval()\n\nsubmission = pd.read_csv(\"../input/cmc-robust-real-vs-fake/submission.csv\")\ntest_paths = [f\"../input/cmc-robust-real-vs-fake/test/{i}.jpg\" for i in submission[\"id\"].values]\n\n\ntest_dataset = RealFakeDataset(\n    test_paths,\n    is_test=True,\n    augmentation=transform_test,\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=config[\"batch_size\"],\n    shuffle=False,\n    num_workers=config[\"num_workers\"],\n    drop_last=False,\n)\nprint(\"Length of the test_loader:\", len(test_loader))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = predict_fn(test_loader, model, config[\"device\"])\nsubmission[\"label\"] = result\nsubmission.to_csv(\"./submission_new.csv\", index=None)\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}